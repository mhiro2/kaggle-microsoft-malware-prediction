import gc
import time
from abc import ABC, abstractmethod
from operator import add, mul, sub, truediv
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd

from utils import convert_camel_to_snake


__all__ = ['Feature']


class Feature(ABC):
    def __init__(self, data_dir='./.cache'):
        self.data_dir = data_dir
        self.train = pd.DataFrame()
        self.test = pd.DataFrame()
        self.column = self.name

    @property
    def name(self) -> str:
        return convert_camel_to_snake(self.__class__.__name__)

    @classmethod
    def get_prefix(cls, *, encode_type) -> str:
        if encode_type == None:
            return ''
        elif encode_type == 'count':
            return 'cnt_'
        elif encode_type == 'category':
            return 'lbl_'
        elif encode_type == 'rank':
            return 'rank_'
        elif encode_type == 'target':
            return 'te_'
        else:
            raise NotImplementedError

    def create(self, train_df, test_df, kfold, encode_type=None):
        if encode_type == 'target':
            self.target = train_df[self.target_column]
            self.kfold = kfold
            self.file_suffix = f'_split{kfold.n_splits}_seed{kfold.random_state}_'

        self._get_save_path(encode_type=encode_type)

        if self.train_path.exists() and self.test_path.exists():
            print(f'Skipped [{self.name}]')
            return False

        print(f'Start computing feature [{self.name}]')
        start_time = time.time()
        self.create_features_from_df(train_df, test_df)

        new_column = f'{self.get_prefix(encode_type=encode_type)}{self.column}'

        # NOTE: 'None' means binary or numerical feature
        if encode_type is None:
            pass
        elif encode_type == 'count':
            self._encode_count(self.train, new_column)
            self._encode_count(self.test, new_column)
        elif encode_type in ('category', 'rank'):
            self._encode_rank(new_column)
        elif encode_type == 'target':
            self._encode_target_mean(new_column)
        else:
            raise NotImplementedError

        self.column = new_column

        if encode_type == 'category':
            self.train[self.column].astype('category')
            self.test[self.column].astype('category')

        self._save()

        elapsed = time.time() - start_time
        print(f'Finished computing feature [{self.name}]: {elapsed:.0f} s')

    def prepare_target(self, target_column):
        self.target_column = target_column

    @abstractmethod
    def create_features_from_df(self, train_df, test_df):
        raise NotImplementedError

    def _encode_count(self, df, new_column):
        df[new_column] = df.groupby(self.column)[self.column].transform('count')
        df.drop(self.column, axis=1, inplace=True)

    def _encode_rank(self, new_column):
        _, indexer = pd.factorize(self.train[self.column].astype(str), sort=True)
        self.train[new_column] = indexer.get_indexer(
                                     self.train[self.column].astype(str)
                                 )
        self.test[new_column] = indexer.get_indexer(
                                    self.test[self.column].astype(str)
                                )
        self.train.drop(self.column, axis=1, inplace=True)
        self.test.drop(self.column, axis=1, inplace=True)

    def _encode_target_mean(self, new_column):
        merged_df = pd.concat([self.train, self.target], axis=1)

        # NOTE: half float (float16) is not supported in feather
        if self.train.dtypes[self.column] == np.float16:
            self.train[self.column] = self.train[self.column].astype('float32')
            self.test[self.column] = self.test[self.column].astype('float32')

        # initialize NaN
        self.train[new_column] = pd.Series(dtype='float32')
        for i in range(self.kfold.n_splits):
            self.test[f'{new_column}_fold{i+1}'] = pd.Series(dtype='float32')

        for i, (train_idx, valid_idx) in enumerate(self.kfold.split(self.target, self.target)):
            train_x = merged_df.iloc[train_idx]
            valid_x = merged_df.iloc[valid_idx]

            target_mean = train_x.groupby(self.column)[self.target_column].mean()
            self.train[new_column].iloc[valid_idx] = valid_x[self.column].map(target_mean)
            self.test[f'{new_column}_fold{i+1}'] = self.test[self.column].map(target_mean).fillna(0.5)

        self.train.drop(self.column, axis=1, inplace=True)
        self.test.drop(self.column, axis=1, inplace=True)

    def _get_save_path(self, *, encode_type):
        prefix = self.get_prefix(encode_type=encode_type)
        suffix = self.file_suffix if hasattr(self, 'file_suffix') else '_'

        self.train_path = (Path(self.data_dir) /
                            f'{prefix}{self.name}{suffix}train.feather')
        self.test_path = (Path(self.data_dir) /
                            f'{prefix}{self.name}{suffix}test.feather')

    def _save(self):
        self.train.to_feather(self.train_path)
        self.test.to_feather(self.test_path)


class GroupCountFeature(Feature):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    @property
    @abstractmethod
    def group_columns(self) -> List[str]:
        raise NotImplementedError

    @property
    @abstractmethod
    def count_column(self) -> str:
        raise NotImplementedError

    def create_features_from_df(self, train_df, test_df):
        column = self.column
        self.train[column] = self._compute(train_df)
        self.test[column] = self._compute(test_df)

    def _compute(self, df):
        if self.count_column in self.group_columns:
            return df[self.group_columns].groupby(
                    self.group_columns)[self.count_column].transform('count').fillna(0)
        else:
            return df[[*self.group_columns, self.count_column]].groupby(
                    self.group_columns)[self.count_column].transform('count').fillna(0)


class AggregateFeature(Feature):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    @property
    @abstractmethod
    def group_columns(self) -> List[str]:
        raise NotImplementedError

    @property
    @abstractmethod
    def aggs(self) -> Dict[str, str]:
        raise NotImplementedError

    def create_features_from_df(self, train_df, test_df):
        new_columns = [f'{self.column}_{k}_{v}' for k, vs in self.aggs.items() for v in vs]
        self.train[new_columns] = self._compute(train_df, new_columns).astype('float32')
        self.test[new_columns] = self._compute(test_df, new_columns).astype('float32')

    def _compute(self, df, new_columns):
        result = df.groupby(self.group_columns).agg(self.aggs).reset_index()
        result.columns = [*self.group_columns, *new_columns]
        return df[self.group_columns].merge(result, on=self.group_columns, how='left')[new_columns]


class ArithmeticFeature(Feature):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    @property
    @abstractmethod
    def column_pair(self) -> List[str]:
        raise NotImplementedError

    def create_features_from_df(self, train_df, test_df):
        column = self.column
        self._define_operator()
        self.train[column] = self._compute(train_df)
        self.test[column] = self._compute(test_df)

    def _define_operator(self):
        cls_name = self.name

        if cls_name.startswith('add'):
            self.op = add
        elif cls_name.startswith('sub'):
            self.op = sub
        elif cls_name.startswith('mul'):
            self.op = mul
        elif cls_name.startswith('div'):
            self.op = truediv
        else:
            raise NotImplementedError

    def _compute(self, df):
        col1, col2 = self.column_pair
        result = self.op(df[col1], df[col2])
        return result.fillna(result.mean()).astype('float32')


class DecompositionFeature(Feature):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    @property
    @abstractmethod
    def n_components(self) -> int:
        raise NotImplementedError

    @property
    @abstractmethod
    def columns(self) -> List[str]:
        raise NotImplementedError

    @abstractmethod
    def preprocess(self, train_df, test_df):
        raise NotImplementedError

    @abstractmethod
    def transformer_factory(self):
        raise NotImplementedError

    def create_features_from_df(self, train_df, test_df):
        self.preprocess(train_df, test_df)
        vectors = self._compute_vectors(train_df, test_df)
        self.train = self._map_vectors_to_df(train_df, vectors)
        self.test = self._map_vectors_to_df(test_df, vectors)

    def _create_cooccurrence_matrix(self, df):
        df[self.columns].fillna(-99, inplace=True)
        group_count = df.groupby(self.columns)[self.columns[0]].count().unstack(fill_value=0)
        index = group_count.index.values.astype(df[self.columns[0]].dtype)
        return group_count, index

    def _compute_vectors(self, train_df, test_df):
        merged_df = pd.concat((train_df[self.columns], test_df[self.columns]))
        matrix, index_cols = self._create_cooccurrence_matrix(merged_df)
        del merged_df
        gc.collect()

        transformer = self.transformer_factory()
        vectors = transformer.fit_transform(matrix).astype('float32')

        column_dict = {i: f'{self.name}_{i+1}' for i in range(self.n_components)}
        return (
            pd.DataFrame(vectors, index=index_cols).reset_index().rename(
                columns={'index': self.columns[0], **column_dict})
        )

    def _map_vectors_to_df(self, df, vectors):
        new_df = df[[self.columns[0]]].merge(vectors, on=self.columns[0], how='left')
        return new_df.drop(self.columns[0], axis=1)

